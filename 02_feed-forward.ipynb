{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a Feed-Forward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This notebook shows how to implement a Feed-Forward neural network\n",
    "\n",
    "<small>Author: Fernando Carlos López Hernández</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializacion\n",
    "First we initializate the nodes of the neurons with the bias and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 0\n",
      "Neuron 0: w:[-1.198, 0.194, -0.605, 0.504] \n",
      "Neuron 1: w:[0.512, -1.61, 0.129, 0.142] \n",
      "Output Layer 1\n",
      "Neuron 0: w:[0.526, 0.513, 1.086] \n",
      "Neuron 1: w:[-0.397, 0.342, -1.218] \n",
      "Neuron 2: w:[0.267, -0.153, -0.887] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_layer(L):\n",
    "    for i, n in enumerate(L):\n",
    "       print(f'Neuron {i}: ', end='')\n",
    "       for key,value in n.items():\n",
    "           print (key, ':', np.round(value,3).tolist(), ' ', sep ='',  end='')\n",
    "       print()\n",
    "    \n",
    "def print_NN(NN):\n",
    "    for i,L in enumerate(NN):\n",
    "        if i<len(NN)-1:\n",
    "            print(f'Hidden Layer {i}')\n",
    "        else:\n",
    "            print(f'Output Layer {i}')\n",
    "        print_layer(L)\n",
    "\n",
    "def init_random_NN(Ns_per_layer):\n",
    "    \"\"\" Create a NN with the number of Ns indicated for each input+hidden+output layer \"\"\"\n",
    "    NN = list()\n",
    "    n_previous = Ns_per_layer[0]\n",
    "    for n in Ns_per_layer[1:]:\n",
    "        layer = [{'w': np.random.normal(0,1, size = n_previous+1)} for i in range(n)]\n",
    "        NN.append(layer)\n",
    "        n_previous = n\n",
    "    return NN\n",
    "\n",
    "NN = init_random_NN([3,2,3])\n",
    "print_NN(NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward propagate algorithm\n",
    "This algorithm propagates the input through the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 0\n",
      "Neuron 0: w:[-1.728, -0.708, -0.091, 0.531] v:-1.291 y:0.216 \n",
      "Neuron 1: w:[-0.068, -1.246, 0.532, 1.501] v:5.044 y:0.994 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[1.151, 0.015, -0.841] v:0.318 y:0.579 \n",
      "Neuron 1: w:[-0.261, -0.417, 0.322] v:-0.031 y:0.492 \n",
      "Neuron 2: w:[-1.432, -1.291, 0.731] v:-0.984 y:0.272 \n"
     ]
    }
   ],
   "source": [
    "def activation_value(weights, inputs):\n",
    "    \"\"\" Computes the activation value of the N \"\"\"\n",
    "    return np.dot(weights, inputs)\n",
    "\n",
    "def sigmoid(v):\n",
    "    return 1.0 / (1.0 + np.exp(-v))\n",
    "\n",
    "def step(v):\n",
    "    if v>0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def forward_propagate(NN, x, transfer_fn):\n",
    "    x = np.concatenate([[1.0],x])\n",
    "    for L in NN:\n",
    "        y = []\n",
    "        for N in L:\n",
    "            N['v'] = activation_value(N['w'], x)\n",
    "            N['y'] = transfer_fn(N['v'])\n",
    "            y.append(N['y'])\n",
    "        x = np.concatenate([[1.0],y])\n",
    "    return y\n",
    "\n",
    "x = np.array([2.0, 3.0, 4.0])\n",
    "forward_propagate(NN, x, sigmoid)\n",
    "print_NN(NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Neural Network implementing the XOR gate\n",
    "\n",
    "The following example implements an XOR gate with a Feed-Forward neural network. Next we show the result of feeding the neural network with the values of the logic gate. We can change the transfer function to a step function to get binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR FEED-FORWARD PROPAGATE WITH x=[0 0]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:-3.0 y:0.047 \n",
      "Neuron 1: w:[-1, 2, 2] v:-1.0 y:0.269 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:-0.671 y:0.338 \n",
      "XOR FEED-FORWARD PROPAGATES: [0 1]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:-1.0 y:0.269 \n",
      "Neuron 1: w:[-1, 2, 2] v:1.0 y:0.731 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:0.773 y:0.684 \n",
      "XOR FEED-FORWARD PROPAGATES: [1 0]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:-1.0 y:0.269 \n",
      "Neuron 1: w:[-1, 2, 2] v:1.0 y:0.731 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:0.773 y:0.684 \n",
      "XOR FEED-FORWARD PROPAGATES: [1 1]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:1.0 y:0.731 \n",
      "Neuron 1: w:[-1, 2, 2] v:3.0 y:0.953 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:-0.671 y:0.338 \n"
     ]
    }
   ],
   "source": [
    "NN_xor = [ # Hidden layer\n",
    "       [{'w':np.array([-3, 2, 2])}, {'w':np.array([-1, 2, 2])}],\n",
    "       # Output layer\n",
    "       [{'w':np.array([-2, -6, 6])}] ]\n",
    "\n",
    "transfer_fn = sigmoid \n",
    "x = np.array([0, 0])\n",
    "forward_propagate(NN_xor, x, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATE WITH x={x}')\n",
    "print_NN(NN_xor)\n",
    "\n",
    "x = np.array([0, 1])\n",
    "forward_propagate(NN_xor, x, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATE WITH x={x}')\n",
    "print_NN(NN_xor)\n",
    "\n",
    "x = np.array([1, 0])\n",
    "forward_propagate(NN_xor, x, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATE WITH x={x}')\n",
    "print_NN(NN_xor)\n",
    "\n",
    "x = np.array([1, 1])\n",
    "forward_propagate(NN_xor, x, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATE WITH x={x}')\n",
    "print_NN(NN_xor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a792fcb311f9eb9f3c1b942a8c87ada8484712b89b670347c16a1088e0a1f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
