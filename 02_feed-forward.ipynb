{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementation of a Feed-Forward neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>This notebook shows how to implement a Feed-Forward neural network\n",
    "\n",
    "<small>Author: Fernando Carlos López Hernández</small>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initializacion\n",
    "First we initializate the nodes of the neurons with the bias and weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 0\n",
      "Neuron 0: w:[-0.898, 0.082, -1.043, -0.986] \n",
      "Neuron 1: w:[-1.434, 0.969, -2.295, -1.786] \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-1.64, 0.756, -2.182] \n",
      "Neuron 1: w:[0.483, -0.428, -0.869] \n",
      "Neuron 2: w:[-0.076, -0.804, -0.198] \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def print_layer(L):\n",
    "    for i, n in enumerate(L):\n",
    "       print(f'Neuron {i}: ', end='')\n",
    "       for key,value in n.items():\n",
    "           print (key, ':', np.round(value,3).tolist(), ' ', sep ='',  end='')\n",
    "       print()\n",
    "    \n",
    "def print_NN(NN):\n",
    "    for l,L in enumerate(NN):\n",
    "        if l<len(NN)-1:\n",
    "            print(f'Hidden Layer {l}')\n",
    "            print_layer(L)\n",
    "            \n",
    "        else:\n",
    "            print(f'Output Layer {l}')\n",
    "            print_layer(L)\n",
    "\n",
    "def init_random_NN(Ns_per_layer):\n",
    "    \"\"\" Create a NN with the number of Ns indicated for each input+hidden+output layer \"\"\"\n",
    "    NN = list()\n",
    "    n_previous = Ns_per_layer.pop(0)\n",
    "    for n in Ns_per_layer:\n",
    "        layer = [{'w': np.random.normal(0,1, size = n_previous+1)} for i in range(n)]\n",
    "        NN.append(layer)\n",
    "        n_previous = n\n",
    "    return NN\n",
    "\n",
    "NN = init_random_NN([3,2,3])\n",
    "print_NN(NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feed-Forward propagate algorithm\n",
    "This algorithm propagates the input through the neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hidden Layer 0\n",
      "Neuron 0: w:[-0.898, 0.082, -1.043, -0.986] v:-7.807 y:0.0 \n",
      "Neuron 1: w:[-1.434, 0.969, -2.295, -1.786] v:-13.524 y:0.0 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-1.64, 0.756, -2.182] v:-1.639 y:0.163 \n",
      "Neuron 1: w:[0.483, -0.428, -0.869] v:0.482 y:0.618 \n",
      "Neuron 2: w:[-0.076, -0.804, -0.198] v:-0.077 y:0.481 \n"
     ]
    }
   ],
   "source": [
    "def activation_value(weights, inputs):\n",
    "    \"\"\" Computes the activation value of the N \"\"\"\n",
    "    return np.dot(weights, inputs)\n",
    "\n",
    "def sigmoid(v):\n",
    "    return 1.0 / (1.0 + np.exp(-v))\n",
    "\n",
    "def step(v):\n",
    "    if v>0.0:\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def forward_propagate(NN, inputs, transfer_fn):\n",
    "    inputs = np.concatenate([[1.0],inputs])\n",
    "    for L in NN:\n",
    "        outputs = []\n",
    "        for N in L:\n",
    "            N['v'] = activation_value(N['w'], inputs)\n",
    "            N['y'] = transfer_fn(N['v'])\n",
    "            outputs.append(N['y'])\n",
    "        inputs = np.concatenate([[1.0],outputs])\n",
    "    return outputs\n",
    "\n",
    "inputs = np.array([2.0, 3.0, 4.0])\n",
    "forward_propagate(NN, inputs, sigmoid)\n",
    "print_NN(NN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Example: Neural Network implementing the XOR gate\n",
    "\n",
    "The following example implements an XOR gate with a Feed-Forward neural network. Next we show the result of feeding the neural network with the values of the logic gate. We can change the transfer function to a step function to get binary values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XOR FEED-FORWARD PROPAGATES: [0 0]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:-3.0 y:0.047 \n",
      "Neuron 1: w:[-1, 2, 2] v:-1.0 y:0.269 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:-0.671 y:0.338 \n",
      "XOR FEED-FORWARD PROPAGATES: [0 1]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:-1.0 y:0.269 \n",
      "Neuron 1: w:[-1, 2, 2] v:1.0 y:0.731 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:0.773 y:0.684 \n",
      "XOR FEED-FORWARD PROPAGATES: [1 0]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:-1.0 y:0.269 \n",
      "Neuron 1: w:[-1, 2, 2] v:1.0 y:0.731 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:0.773 y:0.684 \n",
      "XOR FEED-FORWARD PROPAGATES: [1 1]\n",
      "Hidden Layer 0\n",
      "Neuron 0: w:[-3, 2, 2] v:1.0 y:0.731 \n",
      "Neuron 1: w:[-1, 2, 2] v:3.0 y:0.953 \n",
      "Output Layer 1\n",
      "Neuron 0: w:[-2, -6, 6] v:-0.671 y:0.338 \n"
     ]
    }
   ],
   "source": [
    "NN_xor = [ # Hidden layer\n",
    "       [{'w':np.array([-3, 2, 2])}, {'w':np.array([-1, 2, 2])}],\n",
    "       # Output layer\n",
    "       [{'w':np.array([-2, -6, 6])}] ]\n",
    "\n",
    "transfer_fn = sigmoid \n",
    "inputs = np.array([0, 0])\n",
    "forward_propagate(NN_xor, inputs, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATES: {inputs}')\n",
    "print_NN(NN_xor)\n",
    "\n",
    "inputs = np.array([0, 1])\n",
    "forward_propagate(NN_xor, inputs, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATES: {inputs}')\n",
    "print_NN(NN_xor)\n",
    "\n",
    "inputs = np.array([1, 0])\n",
    "forward_propagate(NN_xor, inputs, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATES: {inputs}')\n",
    "print_NN(NN_xor)\n",
    "\n",
    "inputs = np.array([1, 1])\n",
    "forward_propagate(NN_xor, inputs, transfer_fn)\n",
    "print(f'XOR FEED-FORWARD PROPAGATES: {inputs}')\n",
    "print_NN(NN_xor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7a792fcb311f9eb9f3c1b942a8c87ada8484712b89b670347c16a1088e0a1f69"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
